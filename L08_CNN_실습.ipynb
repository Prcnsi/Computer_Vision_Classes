{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# 7-2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.datasets as ds\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "(x_train,y_train), (x_test,y_test)=ds.mnist.load_data()\n",
        "x_train=x_train.reshape(60000,784)\n",
        "x_test=x_test.reshape(10000,784)\n",
        "x_train=x_train.astype(np.float32)/255.0\n",
        "x_test=x_test.astype(np.float32)/255.0\n",
        "y_train=tf.keras.utils.to_categorical(y_train,10)\n",
        "y_test=tf.keras.utils.to_categorical(y_test,10)\n",
        "\n",
        "mlp=Sequential()\n",
        "mlp.add(Dense(units=512,activation='tanh',input_shape=(784,)))\n",
        "mlp.add(Dense(units=10,activation='softmax'))\n",
        "\n",
        "mlp.compile(loss='MSE',optimizer=SGD(learning_rate=0.01),\n",
        "metrics=['accuracy'])\n",
        "mlp.fit(x_train,y_train,batch_size=128,epochs=50,\n",
        "validation_data=(x_test,y_test),verbose=0)\n",
        "\n",
        "res=mlp.evaluate(x_test,y_test,verbose=0)\n",
        "print('정확률=', res[1]*100)"
      ],
      "metadata": {
        "id": "XKRUNCn5RgPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7-3\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.datasets as ds\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "(x_train,y_train), (x_test,y_test)=ds.mnist.load_data()\n",
        "x_train=x_train.reshape(60000,784)\n",
        "x_test=x_test.reshape(10000,784)\n",
        "x_train=x_train.astype(np.float32)/255.0\n",
        "x_test=x_test.astype(np.float32)/255.0\n",
        "y_train=tf.keras.utils.to_categorical(y_train,10)\n",
        "y_test=tf.keras.utils.to_categorical(y_test,10\n",
        "\n",
        "mlp=Sequential()\n",
        "mlp.add(Dense(units=512,activation='tanh',input_shape=(784,)))\n",
        "mlp.add(Dense(units=10,activation='softmax'))\n",
        "\n",
        "mlp.compile(loss='MSE',optimizer=Adam(learning_rate=0.001),\n",
        "metrics=['accuracy'])\n",
        "mlp.fit(x_train,y_train,batch_size=128,epochs=50,\n",
        "validation_data=(x_test,y_test),verbose=0)\n",
        "\n",
        "res=mlp.evaluate(x_test,y_test,verbose=0)\n",
        "print('정확률=', res[1]*100)"
      ],
      "metadata": {
        "id": "D3PGXleJ8Qcl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7-4\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.datasets as ds\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "\n",
        "(x_train,y_train), (x_test,y_test)=ds.mnist. load_data()\n",
        "x_train=x_train.reshape(60000,784)\n",
        "x_test=x_test.reshape(10000,784)\n",
        "x_train=x_train.astype(np.float32)/255.0\n",
        "x_test=x_test.astype(np.float32)/255.0\n",
        "y_train=tf.keras.utils.to_categorical(y_train,10)\n",
        "y_test=tf.keras.utils.to_categorical(y_test,10)\n",
        "\n",
        "mlp_sgd=Sequential()\n",
        "mlp_sgd.add(Dense(units=512,activation='tanh' ,input_shape=(784,)))\n",
        "mlp_sgd.add(Dense(units=10,activation='softmax'))\n",
        "\n",
        "mlp_sgd.compile(loss='MSE' ,optimizer=SGD(learning_rate=0.01),metrics=['accuracy'])\n",
        "hist_sgd=mlp_sgd.fit(x_train,y_train,batch_size=128,epochs=50,validation_data=(x_test,y_test),verbose=2)\n",
        "print('SGD 정확률=',mlp_sgd.evaluate(x_test,y_test,verbose=0)[1]*100)\n",
        "\n",
        "mlp_adam=Sequential()\n",
        "mlp_adam.add(Dense(units=512,activation='tanh',input_shape=(784,)))\n",
        "mlp_adam.add(Dense(units=10,activation='softmax'))\n",
        "\n",
        "mlp_adam.compile(loss='MSE',optimizer=Adam(Learning_rate=0.001),metrics=['accuracy'])\n",
        "hist_adam=mlp_adam.fit(x_train,y_train,batch_size=128,epochs=50,validation_data=(x_test,y_test),verbose=2)\n",
        "print('Adam 정확률=',mlp_adam.evaluate(x_test,y_test,verbose=0)[1]*100)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(hist_sgd.history['accuracy'],'r-')\n",
        "plt.plot(hist_sgd.history['val_accuracy'],'r')\n",
        "plt.plot(hist_adam.history['accuracy'],'b-')\n",
        "plt.plot(hist_adam.history['val_accuracy'],'b')\n",
        "plt.title('Comparison of SGD and Adam optimizers')\n",
        "plt.ylim((0.7,1.0))\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend(['train_sgd', 'val_sgd', 'train adam', 'val_adam'])\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qMqaFtsx8SBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7-5\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.datasets as ds\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "(x_train,y_train), (x_test,y_test)=ds.mnist.load_data()\n",
        "x_train=x_train.reshape(60000,784)\n",
        "x_test=x_test.reshape(10000,784)\n",
        "x_train=x_train.astype(np.float32)/255.0\n",
        "x_test=x_test.astype(np.float32)/255.0\n",
        "y_train=tf.keras.utils.to_categorical(y_train,10)\n",
        "y_test=tf.keras.utils.to_categorical(y_test,10)\n",
        "\n",
        "dmlp=Sequential()\n",
        "dmlp.add(Dense(units=1024,activation='relu',input_shape=(784,)))\n",
        "dmlp.add(Dense(units=512,activation='relu'))\n",
        "dmlp.add(Dense(units=512,activation='relu'))\n",
        "dmlp.add(Dense(units=10,activation='softmax'))\n",
        "\n",
        "dmlp.compile(loss='categorical_crossentropy' ,optimizer=Adam(learning_rate=0.0001),metrics=['accuracy'])\n",
        "hist=dmlp.fit(x_train,y_train,batch_size=128,epochs=50,validation_data=(x_test,y_test),verbose=2)\n",
        "print('정확률=',dmlp.evaluate(x_test,y_test,verbose=0)[1]*100)\n",
        "\n",
        "dmlp.save('dmlp_trained.h5')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(hist.history['accuracy'])\n",
        "plt.plot(hist.history['val_accuracy'])\n",
        "plt.title('Accuracy graph')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend(['train','test'])\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title('Loss graph')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.legend(['train','test'])\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LeLHN-148TYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7-6\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.datasets as ds\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Reshape\n",
        "from tensorflow.keras.layers import Dropout, BatchNormalization, LeakyReLU\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "(x_train,y_train), (x_test,y_test)=ds.cifar10.load_data() #\n",
        "x_train=x_train.reshape(50000, 32, 32, 3)\n",
        "x_test=x_test.reshape(10000, 32, 32, 3)\n",
        "x_train=x_train.astype(np.float32)/255.0\n",
        "x_test=x_test.astype(np.float32)/255.0\n",
        "\n",
        "\n",
        "dmlp = Sequential()\n",
        "dmlp.add(Reshape((32, 32, 3)))\n",
        "dmlp.add(Conv2D(128, 3, activation='relu',padding=\"same\"))\n",
        "dmlp.add(MaxPooling2D(2))\n",
        "dmlp.add(Conv2D(64, 3, activation='relu',padding=\"same\"))\n",
        "dmlp.add(MaxPooling2D(2))\n",
        "dmlp.add(Flatten())\n",
        "dmlp.add(Dense(128))\n",
        "dmlp.add(Dense(10, activation='softmax'))\n",
        "\n",
        "\n",
        "dmlp.compile(loss='sparse_categorical_crossentropy' ,optimizer=Adam(learning_rate=0.0001),metrics=['accuracy'])\n",
        "hist=dmlp.fit(x_train,y_train,batch_size=128,epochs=10,validation_data=(x_test,y_test),verbose=2)\n",
        "print('정확률=',dmlp.evaluate(x_test,y_test,verbose=0)[1]*100)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(hist.history['accuracy'])\n",
        "plt.plot(hist.history['val_accuracy'])\n",
        "plt.title('Accuracy graph')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend(['train','test'])\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title('Loss graph')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.legend(['train','test'])\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XAXBtxbs8Uvd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7-7\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import cv2 as cv\n",
        "import matplotlib.pyplot as plt\n",
        "import winsound\n",
        "\n",
        "model=tf.keras.models.load_model('dmlp_trained.h5')\n",
        "\n",
        "def reset():\n",
        "    global img\n",
        "\n",
        "    img=np.ones((200,520,3),dtype=np.uint8)*255\n",
        "    for i in range(5):\n",
        "        cv.rectangle(img,(10+i*100,50),(10+(i+1)*100,150),(0,0,255))\n",
        "    cv.putText(img,'e:erace s:show r:recognition q:quit',(10,40),cv.FONT_HERSHEY_SIMPLEX,0.8,(255,0,0),1)\n",
        "\n",
        "def grab_numerals():\n",
        "    numerals=[]\n",
        "\n",
        "    for i in range(5):\n",
        "        roi=img[51:149,11+i*100:9+(i+1)*100,0]\n",
        "        roi=255-cv.resize(roi, (28,28),interpolation=cv.INTER_CUBIC)\n",
        "        numerals.append(roi)\n",
        "    numerals=np.array(numerals)\n",
        "    return numerals\n",
        "\n",
        "def show():\n",
        "    numerals=grab_numerals()\n",
        "    plt.figure(figsize=(25,5))\n",
        "    for i in range(5):\n",
        "        plt.subplot(1,5,i+1)\n",
        "        plt.imshow(numerals[i],cmap='gray')\n",
        "        plt.xticks([]); plt.yticks([])\n",
        "    plt.show()\n",
        "\n",
        "def recognition():\n",
        "    numerals=grab_numerals()\n",
        "    numerals=numerals.reshape(5,784)\n",
        "    numerals=numerals.astype(np.float32)/255.0\n",
        "    res=model.predict(numerals)\n",
        "    class_id=np.argmax(res,axis=1)\n",
        "    for i in range(5):\n",
        "        cv.putText(img,str(class_id[i]),(50+1*100,180),cv.FONT_HERSHEY_SIMPLEX, 1, (255,0,0),1)\n",
        "    winsound.Beep(1000,500)"
      ],
      "metadata": {
        "id": "IyNbtCPI8WoF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}